{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f9b335a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 444/444 [34:08<00:00,  4.61s/it]\n",
      "Extracting test features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 195/195 [13:54<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 1.05849\n",
      "[200]\tvalid_0's rmse: 1.02706\n",
      "[300]\tvalid_0's rmse: 1.0182\n",
      "[400]\tvalid_0's rmse: 1.01707\n",
      "[500]\tvalid_0's rmse: 1.01001\n",
      "[600]\tvalid_0's rmse: 1.00308\n",
      "[700]\tvalid_0's rmse: 1.0007\n",
      "[800]\tvalid_0's rmse: 0.997943\n",
      "[900]\tvalid_0's rmse: 0.996304\n",
      "Early stopping, best iteration is:\n",
      "[893]\tvalid_0's rmse: 0.996112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.953623\n",
      "[200]\tvalid_0's rmse: 0.935478\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's rmse: 0.93119\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.933744\n",
      "[200]\tvalid_0's rmse: 0.859128\n",
      "[300]\tvalid_0's rmse: 0.823599\n",
      "[400]\tvalid_0's rmse: 0.79913\n",
      "[500]\tvalid_0's rmse: 0.789766\n",
      "[600]\tvalid_0's rmse: 0.779637\n",
      "[700]\tvalid_0's rmse: 0.776042\n",
      "[800]\tvalid_0's rmse: 0.773738\n",
      "[900]\tvalid_0's rmse: 0.773488\n",
      "[1000]\tvalid_0's rmse: 0.7725\n",
      "[1100]\tvalid_0's rmse: 0.772691\n",
      "Early stopping, best iteration is:\n",
      "[1055]\tvalid_0's rmse: 0.771745\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.931143\n",
      "[200]\tvalid_0's rmse: 0.875219\n",
      "[300]\tvalid_0's rmse: 0.850787\n",
      "Early stopping, best iteration is:\n",
      "[299]\tvalid_0's rmse: 0.850167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's rmse: 0.971479\n",
      "[200]\tvalid_0's rmse: 0.917342\n",
      "[300]\tvalid_0's rmse: 0.884867\n",
      "[400]\tvalid_0's rmse: 0.872513\n",
      "[500]\tvalid_0's rmse: 0.863441\n",
      "[600]\tvalid_0's rmse: 0.862771\n",
      "Early stopping, best iteration is:\n",
      "[543]\tvalid_0's rmse: 0.861326\n",
      "\n",
      "âœ… Average RÂ² Score: 0.3662\n",
      "ðŸ“ submission2.csv created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "def extract_features(file_path):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=22050)\n",
    "        features = {\n",
    "            \"duration\": librosa.get_duration(y=y, sr=sr),\n",
    "            \"rms\": np.mean(librosa.feature.rms(y=y)),\n",
    "            \"zcr\": np.mean(librosa.feature.zero_crossing_rate(y=y)),\n",
    "            \"tempo\": librosa.beat.tempo(y=y, sr=sr)[0]\n",
    "        }\n",
    "\n",
    "        # MFCCs\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        for i in range(13):\n",
    "            features[f\"mfcc_{i}_mean\"] = np.mean(mfcc[i])\n",
    "            features[f\"mfcc_{i}_std\"] = np.std(mfcc[i])\n",
    "\n",
    "        # Chroma\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        features[\"chroma_mean\"] = np.mean(chroma)\n",
    "        features[\"chroma_std\"] = np.std(chroma)\n",
    "\n",
    "        # Spectral Contrast\n",
    "        contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        features[\"contrast_mean\"] = np.mean(contrast)\n",
    "        features[\"contrast_std\"] = np.std(contrast)\n",
    "\n",
    "        # Tonnetz\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
    "        features[\"tonnetz_mean\"] = np.mean(tonnetz)\n",
    "        features[\"tonnetz_std\"] = np.std(tonnetz)\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract train features\n",
    "train_features = []\n",
    "for filename in tqdm(train_df['filename'], desc=\"Extracting train features\"):\n",
    "    feats = extract_features(os.path.join('audios_train', filename))\n",
    "    if feats is not None:\n",
    "        train_features.append(feats)\n",
    "\n",
    "\n",
    "train_feats = pd.DataFrame(train_features)\n",
    "train_feats[\"label\"] = train_df.loc[train_feats.index, \"label\"]\n",
    "\n",
    "# Extract test features\n",
    "test_features = []\n",
    "for filename in tqdm(test_df['filename'], desc=\"Extracting test features\"):\n",
    "    feats = extract_features(os.path.join('audios_test', filename))\n",
    "    test_features.append(feats)\n",
    "\n",
    "\n",
    "test_feats = pd.DataFrame(test_features)\n",
    "\n",
    "# Handle missing values\n",
    "train_feats.dropna(inplace=True)\n",
    "test_feats.fillna(0, inplace=True)\n",
    "\n",
    "# Split features and labels\n",
    "X = train_feats.drop(\"label\", axis=1)\n",
    "y = train_feats[\"label\"]\n",
    "X_test = test_feats.copy()\n",
    "\n",
    "# Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "val_scores = []\n",
    "\n",
    "# LightGBM model parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"num_leaves\": 64,\n",
    "    \"max_depth\": -1,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"verbosity\": -1,\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Train and validate\n",
    "final_preds = np.zeros(len(X_test_scaled))\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[val_data],\n",
    "    num_boost_round=2000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "    score = r2_score(y_val, val_pred)\n",
    "    val_scores.append(score)\n",
    "\n",
    "    # Predict on test set and add to final_preds\n",
    "    final_preds += model.predict(X_test_scaled) / kf.n_splits\n",
    "\n",
    "print(f\"\\nâœ… Average RÂ² Score: {np.mean(val_scores):.4f}\")\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": test_df[\"filename\"],\n",
    "    \"label\": final_preds.clip(1, 5)\n",
    "})\n",
    "submission.to_csv(\"submission2.csv\", index=False)\n",
    "print(\"ðŸ“ submission2.csv created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
